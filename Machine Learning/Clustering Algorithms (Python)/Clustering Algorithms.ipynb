{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randIndex(truth, predicted):\n",
    "    \"\"\"\n",
    "    The function is to measure similarity between two label assignments\n",
    "    truth: ground truth labels for the dataset (1 x 1496)\n",
    "    predicted: predicted labels (1 x 1496)\n",
    "    \"\"\"\n",
    "    if len(truth) != len(predicted):\n",
    "        print(\"different sizes of the label assignments\");\n",
    "        return -1;\n",
    "    elif (len(truth) == 1):\n",
    "        return 1;\n",
    "    sizeLabel = len(truth);\n",
    "    agree_same = 0;\n",
    "    disagree_same = 0;\n",
    "    count = 0;\n",
    "    for i in range(sizeLabel-1):\n",
    "        for j in range(i+1,sizeLabel):\n",
    "            if ((truth[i] == truth[j]) and (predicted[i] == predicted[j])):\n",
    "                agree_same += 1;\n",
    "            elif ((truth[i] != truth[j]) and (predicted[i] != predicted[j])):\n",
    "                disagree_same +=1;\n",
    "            count += 1;\n",
    "            \n",
    "    return (agree_same+disagree_same)/float(count);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Question 1\n",
    "# parse data\n",
    "feature_file = open(\"dataDescriptions.txt\");\n",
    "feature_names = np.array(feature_file.readline().split(\"^\"));\n",
    "feature_names = feature_names[1:];\n",
    "\n",
    "files = np.array([]);\n",
    "grains_file = open(\"dataCereal-grains-pasta.txt\");\n",
    "vegetables_file  = open(\"dataVegetables.txt\");\n",
    "fats_file = open(\"dataFats-oils.txt\");\n",
    "fish_file = open(\"dataFinfish-shellfish.txt\");\n",
    "files = np.append(files, [grains_file, vegetables_file, fats_file, fish_file]);\n",
    "\n",
    "feature_matrix = np.array([]).reshape(0,len(feature_names));\n",
    "names = np.array([]);\n",
    "ground_truth = np.array([]);\n",
    "lbl = -1;\n",
    "\n",
    "size_dict = {};\n",
    "\n",
    "for file in files:\n",
    "    lbl += 1;\n",
    "    i = 0;\n",
    "    for curr_line in file:\n",
    "        i += 1;\n",
    "        feat = np.array(curr_line.split(\"^\"));\n",
    "        names = np.append(names,feat[0]);\n",
    "        ground_truth = np.append(ground_truth,lbl);\n",
    "        feature_matrix = np.vstack((feature_matrix,feat[1:-1].astype(np.float64)));\n",
    "    size_dict[lbl] = i;\n",
    "        \n",
    "# normalize\n",
    "amax = np.array([]);\n",
    "amin = np.array([]);\n",
    "size = feature_matrix.shape;\n",
    "\n",
    "for i in range(size[1]):\n",
    "    amax = np.append(amax,np.amax(feature_matrix[:,i]));\n",
    "    amin = np.append(amin,np.amin(feature_matrix[:,i]));\n",
    "\n",
    "for i in range(size[0]):\n",
    "    for j in range(size[1]):\n",
    "        if(amax[j]-amin[j]>0):\n",
    "            feature_matrix[i,j] = (feature_matrix[i,j] - amin[j])/(amax[j]-amin[j]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Question 2\n",
    "clf = KMeans(n_clusters=4);\n",
    "clf.fit(feature_matrix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Question 3\n",
    "perm = np.copy(ground_truth);\n",
    "np.random.shuffle(perm);\n",
    "print(randIndex(ground_truth, perm));\n",
    "\n",
    "pred = clf.predict(feature_matrix);\n",
    "print(randIndex(ground_truth, pred));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Question 4\n",
    "J = np.array([]);\n",
    "clf = KMeans(n_clusters=4,n_init=1,init='random');\n",
    "for i in range(20):\n",
    "    clf.fit(feature_matrix);\n",
    "    pred = clf.predict(feature_matrix);\n",
    "    ri = randIndex(ground_truth, pred);\n",
    "    J = np.append(J , {'obj' : clf.inertia_, 'ri' : ri});\n",
    "print(J);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quesiton 5\n",
    "s_feats = np.array([]).reshape(0,len(feature_names));\n",
    "s_names = np.array([]);\n",
    "count = 0;\n",
    "for i in range(4):\n",
    "    a = np.copy(feature_matrix[count:count+size_dict[i]]);\n",
    "    b = np.copy(names[count:count+size_dict[i]]);\n",
    "    count += size_dict[i];\n",
    "    \n",
    "    s = np.random.get_state();\n",
    "    np.random.shuffle(a);\n",
    "    np.random.set_state(s);\n",
    "    np.random.shuffle(b);\n",
    "    s_feats = np.vstack((s_feats,a[:30]));\n",
    "    s_names = np.append(s_names, b[:30]);\n",
    "    \n",
    "fig = plt.figure();\n",
    "data = s_feats;\n",
    "datalable = s_names;\n",
    "hClsMat = sch.linkage(data, method='complete'); # Complete clustering\n",
    "sch.dendrogram(hClsMat, labels=datalable, leaf_rotation=90);\n",
    "fig.savefig(\"dendo_rand\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5305528231359433\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "data = feature_matrix;\n",
    "datalable = names;\n",
    "hClsMat = sch.linkage(data, method='complete');\n",
    "resultingClusters = sch.fcluster(hClsMat,t=3.8, criterion = 'distance');\n",
    "print(randIndex(ground_truth,resultingClusters));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1.0\n",
      "1.1\n",
      "1.2\n",
      "1.3\n",
      "1.4\n",
      "1.5\n",
      "1.6\n",
      "1.7\n",
      "1.8\n",
      "1.9\n",
      "2.0\n",
      "2.1\n",
      "2.2\n",
      "2.3\n",
      "2.4\n",
      "2.5\n",
      "2.6\n",
      "2.7\n",
      "2.8\n",
      "2.9\n",
      "3.0\n",
      "3.1\n",
      "3.2\n",
      "3.3\n",
      "3.4\n",
      "3.5\n",
      "3.6\n",
      "3.7\n"
     ]
    }
   ],
   "source": [
    "results = np.array([]).reshape(0,3);\n",
    "for i in np.arange(.1,3.8,.1):\n",
    "    resultingClusters = sch.fcluster(hClsMat,t=i,criterion='distance');\n",
    "    clusters = len(np.unique(resultingClusters));\n",
    "    ri = randIndex(ground_truth,resultingClusters);\n",
    "    results = np.vstack((results,np.array([i,clusters,ri])));\n",
    "print(results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42.  57.  34.  45.   4.]\n",
      "[ 13.  43.  35.  15.   2.   3.  14.  26.  17.  14.]\n",
      "[ 14.  21.  12.  11.   1.   1.   4.  29.   4.  15.  16.   8.   8.   5.   1.\n",
      "   2.  11.   2.   1.   1.   1.   1.   5.   1.   7.]\n",
      "[  7.   9.  11.   5.   1.   6.   2.   4.   5.   6.   1.   4.   1.   1.  24.\n",
      "   6.   1.   1.   5.   4.   4.   1.   4.   1.   1.   1.   3.   1.   4.   1.\n",
      "   1.   4.   2.   5.   4.   2.   2.   1.   5.   1.   4.   3.   1.   5.   2.\n",
      "   1.   6.   1.   6.   1.]\n",
      "[ 17.   2.   2.   1.   4.   1.   3.   2.   5.   1.   1.   6.   1.   1.   4.\n",
      "   1.   1.   4.   5.   4.   1.   1.   1.   3.   1.  11.   5.   4.   6.   6.\n",
      "   1.   1.   2.   2.   1.   2.   1.   2.   1.   1.   2.   3.   2.   1.   2.\n",
      "   1.   1.   1.   2.   2.   3.   3.   1.   2.   1.   1.   1.   5.   1.   1.\n",
      "   1.   1.   2.   2.   1.   1.   2.   1.   3.   1.   1.   2.   3.   1.   5.]\n",
      "{75: {'items': array(['RICE,WHITE,LONG-GRAIN,PARBLD,UNENR,CKD',\n",
      "       'RICE,WHITE,MEDIUM-GRAIN,CKD', 'RICE NOODLES,CKD', 'MILLET,COOKED',\n",
      "       'RICE,BROWN,MEDIUM-GRAIN,CKD',\n",
      "       'RICE,WHITE,LONG-GRAIN,REG,CKD,ENR,W/SALT',\n",
      "       'RICE,WHITE,LONG-GRAIN,REG,CKD,UNENR,WO/SALT',\n",
      "       'RICE,WHITE,GLUTINOUS,CKD', 'RICE,WHITE,MEDIUM-GRAIN,CKD,UNENR',\n",
      "       'RICE,WHITE,SHORT-GRAIN,CKD'], \n",
      "      dtype='<U43'), 'size': 17.0}, 25: {'items': array(['QUINOA,CKD', 'RICE,WHITE,LONG-GRAIN,REG,CKD,UNENR,W/SALT',\n",
      "       'RICE,WHITE,SHORT-GRAIN,CKD', 'BARLEY,PEARLED,COOKED',\n",
      "       'BULGUR,COOKED', 'SPELT,CKD',\n",
      "       'RICE,WHITE,LONG-GRAIN,PARBLD,ENR,CKD',\n",
      "       'RICE,WHITE,LONG-GRAIN,PARBLD,UNENR,CKD',\n",
      "       'RICE,WHITE,GLUTINOUS,CKD', 'MILLET,COOKED'], \n",
      "      dtype='<U45'), 'size': 29.0}, 10: {'items': array(['BULGUR,COOKED', 'NOODLES,JAPANESE,SOBA,CKD', 'OAT BRAN,COOKED',\n",
      "       'RICE,WHITE,LONG-GRAIN,REG,CKD,UNENR,W/SALT',\n",
      "       'RICE,WHITE,LONG-GRAIN,PRECKD OR INST,ENR,PREP',\n",
      "       'PASTA,FRESH-REFRIGERATED,PLN,CKD', 'RICE,BROWN,LONG-GRAIN,CKD',\n",
      "       'COUSCOUS,COOKED', 'SPELT,CKD',\n",
      "       'PASTA,FRESH-REFRIGERATED,SPINACH,CKD'], \n",
      "      dtype='<U45'), 'size': 43.0}, 50: {'items': array(['RICE,WHITE,LONG-GRAIN,REG,CKD,UNENR,W/SALT', 'PASTA,CORN,COOKED',\n",
      "       'RICE,BROWN,LONG-GRAIN,CKD', 'RICE,WHITE,MEDIUM-GRAIN,CKD',\n",
      "       'RICE,WHITE,SHORT-GRAIN,CKD', 'RICE,WHITE,GLUTINOUS,CKD',\n",
      "       'RICE,BROWN,MEDIUM-GRAIN,CKD', 'WILD RICE,COOKED',\n",
      "       'RICE NOODLES,CKD', 'MILLET,COOKED'], \n",
      "      dtype='<U43'), 'size': 24.0}, 5: {'items': array(['QUINOA,CKD', 'WHEAT,SPROUTED', 'SPAGHETTI,CKD,ENR,WO/ SALT',\n",
      "       'WILD RICE,COOKED', 'RICE,BROWN,LONG-GRAIN,CKD',\n",
      "       'SPAGHETTI,SPINACH,COOKED',\n",
      "       'MACARONI,PROTEIN-FORTIFIED,CKD,ENR,(N X 5.70)', 'SPELT,CKD',\n",
      "       'SPAGHETTI,WHOLE-WHEAT,CKD', 'NOODLES,EGG,CKD,ENR,W/ SALT'], \n",
      "      dtype='<U46'), 'size': 57.0}}\n"
     ]
    }
   ],
   "source": [
    "# Quesiton 7\n",
    "grains_matrix = feature_matrix[0:size_dict[0]];\n",
    "grains_names = names[0:size_dict[0]];\n",
    "\n",
    "clusters = [5, 10, 25, 50 ,75]\n",
    "max_names = {};\n",
    "for i in range(len(clusters)):\n",
    "    clf = KMeans(n_clusters=clusters[i]);\n",
    "    clf.fit(grains_matrix);\n",
    "    sizes = np.array([]);\n",
    "    for j in range(clusters[i]):\n",
    "        sizes = np.append(sizes, np.sum(clf.labels_==j))\n",
    "    max_label_size = np.amax(sizes);\n",
    "    max_label_index = np.where(sizes == max_label_size);\n",
    "    max_clust_names = np.array([]);\n",
    "    for j in range(len(clf.labels_)):\n",
    "        if(clf.labels_[j] == max_label_index):\n",
    "            max_clust_names = np.append(max_clust_names,grains_names[j]);\n",
    "    if(max_label_size<10):\n",
    "        max_names[clusters[i]] = {\"size\" : max_label_size, \"items\" : max_clust_names};\n",
    "    else:\n",
    "        np.random.shuffle(max_clust_names);\n",
    "        max_names[clusters[i]] = {\"size\" : max_label_size, \"items\" : max_clust_names[:10]};\n",
    "print(max_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': array(['RICE,WHITE,LONG-GRAIN,PARBLD,ENR,CKD', 'BARLEY,PEARLED,COOKED',\n",
       "        'RICE,WHITE,MEDIUM-GRAIN,CKD,UNENR', 'RICE,WHITE,SHORT-GRAIN,CKD',\n",
       "        'RICE,WHITE,LONG-GRAIN,PARBLD,UNENR,CKD',\n",
       "        'RICE,WHITE,SHORT-GRAIN,CKD,UNENR',\n",
       "        'RICE,WHITE,LONG-GRAIN,REG,CKD,UNENR,WO/SALT',\n",
       "        'RICE,WHITE,LONG-GRAIN,REG,CKD,ENR',\n",
       "        'RICE,WHITE,LONG-GRAIN,REG,CKD,ENR,W/SALT', 'MILLET,COOKED'], \n",
       "       dtype='<U43'), 'size': 13.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
